## 回归树  
  
### 总结与思考  
1. 使用过滤数组的使用：数组数据的划分可以使用过滤数组的方式     
2. numpy读取数组值的方式总结： 
    1. 索引访问arr[index],一维以上可使用坐标的形式,其实小括号可以去掉，不过为了更好地理解建议将其加上小括号理解为坐标arr[(x,y...)]  
    2. 切片访问arr[start:end:step]      
    3. 指定行arr[[start:end]:[start:end]],最后返回的数据[(start,start).....(end,end)]     
3. 交叉验证,训练集，测试集，评估集  
    * 交叉验证：在给定的建模样本中，拿出大部分样本进行建模型，留小部分样本用刚建立的模型进行预报，
    并求这小部分样本的预报误差，记录它们的平方加和。这个过程一直进行，直到所有的样本都被预报了一次而且仅被预报一次。
    把每个样本的预报误差平方加和      
    * 训练集：数据集中选出来的最大的一部分，顾名思义是拿来训练      
    * 测试集：用来测试模型准确的数据集，一般会计算错误率     
    * 评估集：用来计算方差和的一部分数据，主要用来评估是否存在过拟合       
4. 在拟合这一块，需要较为完善的统计学知识，这也是后期需要完善的部分，虽然神经网络是未来，但是基于统计学的机器学习依然很重要     
5. 关于机器学习库的学习也应该安排到学习计划之中，如sklearn      
6. 树回归的问题，由于每个节点本质上依然是离散的点集，当数据足够大时，为了保持连续性必然会产生大量叶子节点，就好像微分思想中
    
### Q问题栏    
1. 这些现有的方法产生的原理，比如为什么选择方差，方差和，甚至在其它算法中，在某些算法的选择上，其背后的原因又是有何考量呢，  
我们必须搞懂每一个知识点，最后的结果应该是弄明白所有这些已经存在算法包括每一个细节      



